{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8598eb60-099e-4451-b5d2-6909a4d39bf2",
   "metadata": {},
   "source": [
    "# Simple Twitter Raffle Helper\n",
    "\n",
    "This is a simple twitter raffle helper focused on allowing artists that use twitter for raffles to be able to quickly collect the data they need without the need for 3rd party providers or for paying for api's that will used infrequently to facilitate promotional raffles.\n",
    "\n",
    "## Quickstart\n",
    "\n",
    "Follow [this](http://tbd) tutorial to collect the data on the tweet. Add them to the root of this project directory and run:\n",
    "\n",
    "```bash\n",
    "# Note, for linux and mac users you may have to replace pip/python with pip3/python3\n",
    "pip install jupyter-lab\n",
    "python -m jupyter nbconvert --execute --to html results.html\n",
    "```\n",
    "\n",
    "You should have a list of eligible twitter accounts in the `eligible_accounts.csv` and a `results.html` file. You can use the reults file directly to make your pick or you can use the `eligible_accounts.csv` for other 3rd party random pickers.\n",
    "\n",
    "## Data injest \n",
    "\n",
    "Next we'll read in the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d44a2ec-89a4-40eb-a974-2633f49f2d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def open_har(file_path):\n",
    "    with open(file_path, 'r', encoding='utf8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "initial_load = open_har('initial_load.har')\n",
    "liked_by = open_har('liked_by.har')\n",
    "retweeted_by = open_har('retweeted_by.har')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d068ab-dbb1-4192-9e5b-5df08c70a327",
   "metadata": {},
   "source": [
    "## Likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ad144f6-e8c9-4a05-be84-e9587b21008a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_parse(text):\n",
    "    try:\n",
    "        return json.loads(text)\n",
    "    except:\n",
    "        return {}\n",
    "\n",
    "def get_screen_names(raw_data, data_key):\n",
    "    response_content = [c['response']['content'] for c in raw_data['log']['entries'] if 'https://twitter.com/i/api/graphql' in c['request']['url']]\n",
    "    parsed_data = [try_parse(c.get('text','{}')) for c in response_content]\n",
    "    parsed_data = [d for d in parsed_data if 'data' in d]\n",
    "    screen_names = []\n",
    "    for data in parsed_data:\n",
    "        instructions = data.get('data',{}).get(data_key,{}).get('timeline',{}).get('instructions', [])\n",
    "        for instruction in instructions:\n",
    "            if instruction['type'] == 'TimelineAddEntries':\n",
    "                for entry in instruction.get('entries',[]):\n",
    "                    screen_name = entry.get('content').get('itemContent',{}).get('user_results',{}).get('result',{}).get('legacy',{}).get('screen_name', None)\n",
    "                    if screen_name:\n",
    "                        yield screen_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d0275fd-f710-4792-82ce-ec0f30da40f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1054"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "likes = list(get_screen_names(liked_by, 'favoriters_timeline'))\n",
    "len(likes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04c40b14-7f21-439c-97eb-e77070f70437",
   "metadata": {},
   "source": [
    "## Retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0eebcebc-9130-4ea1-9ec6-85e139fe6e20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "167"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "retweets = list(get_screen_names(retweeted_by, 'retweeters_timeline'))\n",
    "len(retweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263ae873-b697-4146-b0b9-cf04262892df",
   "metadata": {},
   "source": [
    "## Eligible Screen Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83feae66-6919-4d10-90d0-b58c87206c80",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "157"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eligible = list(set(retweets).intersection(likes))\n",
    "len(eligible)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f506cc-3b56-43f9-92b0-0d1c04c93e39",
   "metadata": {},
   "source": [
    "## Random Winners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b1784f2-baca-47b2-ae10-9d797db04edf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CoyoteCocktail']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "results = []\n",
    "# NOTE: Need to keep results as a list since set() will force alphabetical order\n",
    "while len(set(results)) < 1:\n",
    "    results.append(random.choice(eligible))\n",
    "display(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ee2d80c-c3dc-4ba8-a49b-f685a43617db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
